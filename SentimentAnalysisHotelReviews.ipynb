{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3RK4+PL9gfadrntxlDbVn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/princedede/Data-Analysis-Projects/blob/main/SentimentAnalysisHotelReviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "4qA2Il7Yxrk6",
        "outputId": "d17f7edf-dc5b-4337-c96f-d6b1b60e0f42"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8b9e0c83bff0>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0memoji\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mydata_profiling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'emoji'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import regex\n",
        "\n",
        "import pandas as pd\n",
        "import pandas_datareader.data as pdr\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#use the following if stopwords isnt installed\n",
        "#nltk.download('stopwords')\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from textblob import TextBlob\n",
        "import string\n",
        "import re\n",
        "import emoji\n",
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "\n",
        "# importing csv file\n",
        "\n",
        "dataframe_3 = pd.read_csv('7282_1.csv')\n",
        "\n",
        "#change reviews.text to reviews\n",
        "dataframe_3 = dataframe_3.rename(columns={'reviews.text': 'reviews'})\n",
        "\n",
        "#selecting needed columns\n",
        "\n",
        "df=dataframe_3[[\"name\",\"reviews.rating\",\"reviews\"]]\n",
        "\n",
        "#check for missing values\n",
        "\n",
        "check_missing_val_total=df.isnull().sum()\n",
        "\n",
        "#assigning grade to ratings\n",
        "rating_high= df[df[\"reviews.rating\"]==5]\n",
        "print(\"rating high:\",rating_high)\n",
        "\n",
        "rating_mid=df[df[\"reviews.rating\"]==3]\n",
        "print(\"rating_mid:\",rating_mid)\n",
        "\n",
        "rating_low=df[df[\"reviews.rating\"]==1]\n",
        "print(\"rating_low:\",rating_low)\n",
        "\n",
        "#grouping by name and finding the mean\n",
        "\n",
        "x=(df.groupby('name')['reviews.rating'].mean())\n",
        "print(x)\n",
        "\n",
        "#plotting ratings reviews.\n",
        "\n",
        "plt.hist(df['reviews.rating'], bins = 5)\n",
        "plt.show()\n",
        "\n",
        "# Lower casing\n",
        "\n",
        "# Change the reviews type to string\n",
        "#df['reviews'] = df.loc[:, ('reviews')].astype(str)\n",
        "df['reviews'] = df['reviews'].astype(str)\n",
        "\n",
        "#Lowercase all reviews\n",
        "df['reviews']= df['reviews'].apply(lambda x: x.lower())\n",
        "print(df['reviews'][2]) ## to see the difference\n",
        "\n",
        "#check if there is any special character\n",
        "alphabet = string.ascii_letters+string.punctuation\n",
        "print(df.reviews.str.strip(alphabet).astype(bool).any())\n",
        "\n",
        "extracted_emojis=[]\n",
        "\n",
        "def extract_emojis(s):\n",
        "    expe = re.compile('[\\U00010000-\\U0010ffff]', flags=re.UNICODE)\n",
        "    #return expe.findall(s)\n",
        "    return expe.sub(r'',s)\n",
        "\n",
        "for y in df['reviews']:\n",
        "    #print(str(extract_emojis(y)))\n",
        "    extracted_emojis.append(str(extract_emojis(y)))\n",
        "\n",
        "    # stop words\n",
        "\n",
        "stop_words=stopwords.words('english')\n",
        "df['extracted_emojis'] = extracted_emojis\n",
        "df['extracted_emojis']= df['extracted_emojis'].apply(lambda x:x if x not in stop_words else None)\n",
        "print(df['extracted_emojis'][5])\n",
        "\n",
        "# stemming\n",
        "\n",
        "def stemming(x):\n",
        "    st = PorterStemmer()\n",
        "    if x is not None:\n",
        "       for word in x.split():\n",
        "           st.stem(word)\n",
        "\n",
        "df['extracted_emojis'].apply(lambda x:stemming(x))\n",
        "print(df['extracted_emojis'][100])\n",
        "\n",
        "#Function to calculate sentiment score for whole data set\n",
        "\n",
        "def senti_sc(x):\n",
        "    if x is not None:\n",
        "       return TextBlob(x).sentiment\n",
        "\n",
        "df[\"Sentiment_score\"]= df[\"extracted_emojis\"].apply(senti_sc)\n",
        "print(df.loc[0:19,['extracted_emojis','Sentiment_score']])\n",
        "\n"
      ]
    }
  ]
}